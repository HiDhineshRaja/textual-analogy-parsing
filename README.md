# Textual Analogy Parsing


Textual Analogy Parsing (TAP) is the task of identifying analogy frames from text. Analogy frames are a discourse-aware shallow semantic representation that highlights points of similarity and difference between analogous facts. 

Given the following sentence

> According to the U.S. Census, almost 10.9 million African Americans, or 28%, live at or below the poverty line, compared with 15% of Latinos and approximately 10% of White Americans.
 
a TAP parser outputs the following analogy frame:

<p align="center"> <img src="figures/avm.png" width=300></p>

TAP frames can be used to automatically plot quantitative facts. The following was generated by assigning elements of the *compared content* from the above frame (in the curly brackets) to the x- and y- axes of a plot, and assigning elements of the *shared content* (in the outer-tier of the frame) to scopal plot elements like titles and axis labels:

<p align="center"> <img src="figures/plot.png" width=200></p>

## Dataset

We report experiments in the paper on a hand-annotated dataset of quantitative analogy frames identified in the Penn Treebank WSJ Corpus. 

The data are available for download here.

Some statistics: 

<p align="center"> <img src="figures/dataset_stats.png"></p>

Here, *Count* refers to the number of frames and *Length* refers to the number of values compared within a given frame. *Av(erage)* is the per-sentence average over a given dataset and *max(imum)* is the maximum over all sentences. *Tot(al)* is the total number of frames in a given dataset.

## Reproducing results

### Installing Gurobi
Our code using the excellent [Gurobi]() ILP solver to enforce TAP constraints (see Section 4 of the paper for more details here). The provided Makefile will download and install the right version of Gurobi, but you will need to obtain a Gurobi license from [here]().

Note: our code _requires_ Python 3.6.

We have provided our trained models in the `models/` directory. By running `make results`

